# Capstone Project 2 - Toxic Comment Classification

## Introduction
There is an increasingly high number of toxic behaviour and comments over the internet which are making it difficult to have meaningful discussion on the net. As the world is becoming more and more technologically involved and people demonstrate more presence on the internet compared to in real life, it is important to make it a healthy and safe place to express opinions. 
One does not need to look far but at Youtube, where presence of toxic and hatred comments in ubiquitous in almost any video. This has led many Youtube channels to disable the comment section, which in itself might be a bit of an extreme measure given the fact that genuine commentators might be interested in the content and want to engage in meaningful discussion. The need for a mechanism to deal with outright toxic and unhealthy comments are more than ever relevant in this day and age.

## The Dataset

Dataset: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/
The dataset chosen for addressing this issues is the Toxic Comment Classification Challenge by Kaggle that was published in March 2018. Conversation AI is a research initiative by Jigsaw and Google aiming at improving online conversation. They have created a lot of publicly available models but there are still errors involved. This competition challenged other to find a model that can better detect negative online behaviour.
This dataset contains Wikipedia comments that have been rated for toxic behaviour. There are 6 classes for 6 types of toxic behaviour including: toxic, severe_toxic, obscene, threat, insult, identity_hate. There are 159,571 comments in the training set (which also includes comments that are rated as neutral, meaning being scored 0 for all classes). The test set include 63,978 comments.

## Files included in this folder
1. Capstone 2 Report
2. Codes
3. Presentation Slides
